{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 9 - CNN - Backpropagation: Optimierer\n",
    "\n",
    "Dieses Notebook thematisiert die Optimierung mittels Stochastic Gradient Descent (SGD) mit Mini-Batches, klassischem Momentum und Weight Decay.\n",
    "\n",
    "Ziel ist es, den Gradientenfluss während der Backpropagation genau zu analysieren und nachzuimplementieren.\n",
    "\n",
    "Dieses Notebook vereint alle bisher betrachteten NumPy-Implementierungen und fügt sie zu einem kompletten Trainingsschritt zusammen.\n",
    "\n",
    "### Inhaltsverzeichnis\n",
    "- [(b) Implementierung des CNN in NumPy und Berechnung der Gradienten](#b)\n",
    "    - [Implementierung der Klasse Linear](#linear)\n",
    "    - [Implementierung der Klasse SoftmaxCrossEntropy](#softmax_cross_entropy)\n",
    "    - [Implementierung des gesamten Netzwerks](#netzwerk)\n",
    "- [(d) Implementierung der Optimierung](#d)\n",
    "- [(e) Reproduktion mit PyTorch](#e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "### Vorbereitung\n",
    "Der Übersicht halber sind einige Funktionalitäten in ein separates Paket ausgelagert. Grundvoraussetzung für deren Verwendung ist, dass Sie das Paket `tui-dl4cv` <font color=\"#aa0000\">installieren bzw. aktualisieren</font> und anschließend importieren.\n",
    "\n",
    "Für die Installation stehen Ihnen zwei mögliche Wege zur Verfügung.\n",
    "\n",
    "**(1) Installation direkt in diesem Notebook:**\n",
    "Führen Sie den nachfolgenden Code-Block aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"Automatically install package for '{sys.executable}'\")\n",
    "!{sys.executable} -m pip install tui-dl4cv \\\n",
    "    --extra-index-url \"https://2023ws:QSv2EKuu9MmyPAZzez82@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" \\\n",
    "    --no-cache --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ODER\n",
    "\n",
    "**(2) Manuelle Installation über die Konsole:**\n",
    "Öffnen Sie eine Konsole (\"Anaconda Prompt\" unter Windows) und führen Sie folgenden Befehl aus:\n",
    "```text\n",
    "pip install tui-dl4cv --extra-index-url \"https://2023ws:QSv2EKuu9MmyPAZzez82@nikrgl.informatik.tu-ilmenau.de/api/v4/projects/1730/packages/pypi/simple\" --no-cache --upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Führen Sie abschließend folgenden Code-Block aus, um das Paket verwenden zu können.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tui_dl4cv.cnn import print_tensors\n",
    "\n",
    "# bisherige Implementierungen wiederverwenden\n",
    "from tui_dl4cv.cnn import MaxPooling\n",
    "from tui_dl4cv.cnn import StandardConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"b\"></a>\n",
    "### (b) Implementieren Sie das gegebene CNN mithilfe von NumPy und berechnen Sie die Gradienten für alle Gewichte.\n",
    "\n",
    "Greifen Sie für die Convolution und das Max-Pooling auf die Klassen `StandardConvolution` und `MaxPooling` aus den bisherigen Notebooks zurück. Beide Klassen wurden bereits importiert und stehen in diesem Notebook zur Verfügung. Beachten Sie, dass die Klasse `StandardConvolution` zur Vereinfachung der Backpropagation ihre Eingabe automatisch speichert. Während der Backpropagation muss daher nicht noch einmal der Input übergeben werden.\n",
    "\n",
    "Im Folgenden sollen die zur Realisierung noch fehlenden Teile implementiert werden:\n",
    "- eine Klasse `Linear` zur Realisierung einer vollverschalteten Schicht\n",
    "- eine Klasse `SoftmaxCrossEntropy` zur Realisierung der Softmax-Ausgabe und anschließender Fehlerbestimmung in Form der Kreuzentropie\n",
    "\n",
    "---\n",
    "Pakete importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"linear\"></a>\n",
    "*Implementierung Klasse `Linear`:*\n",
    "\n",
    "Beachten Sie, dass der Input Tensor in dieser Klasse ebenfalls zwischengespeichert wird, damit er anschließend zur Bestimmung der Gradienten für die Gewichtsmatrix wiederverwendet werden kann.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Funktion könnte für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.dot</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.dot.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, weight_tensor, bias_tensor):\n",
    "        # Gewichte speichern\n",
    "        self.weight = weight_tensor\n",
    "        self.bias = bias_tensor\n",
    "\n",
    "        # zum Speichern des aktuellen Input Tensors\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # Input Tensor speichern\n",
    "        self.x = input_tensor\n",
    "\n",
    "        return    # bitte Code ergaenzen <---------------- [Luecke (1)]\n",
    "\n",
    "    def backward_bias(self, output_tensor_grad):\n",
    "        return    # bitte Code ergaenzen <---------------- [Luecke (2)]\n",
    "\n",
    "    def backward_weight(self, output_tensor_grad):\n",
    "        return    # bitte Code ergaenzen <---------------- [Luecke (3)]\n",
    "\n",
    "    def backward_input(self, output_tensor_grad):\n",
    "        return    # bitte Code ergaenzen <---------------- [Luecke (4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"softmax_cross_entropy\"></a>\n",
    "*Implementierung Klasse `SoftmaxCrossEntropy`:*\n",
    "\n",
    "Beachten Sie, dass zunächst für jedes Beispiel im Batch getrennt die Softmax-Ausgabe und anschließend der Fehler in Form der Kreuzentropie berechnet werden.\n",
    "Abschließend werden die Fehler auf ein Skalar reduziert, welches den Startpunkt für die Backpropagation bildet.\n",
    "\n",
    "In der Regel erfolgt die Reduktion durch eine Mittelwertbildung.\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Funktionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.log</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.log.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.sum</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.sum.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.zeros</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxCrossEntropy:\n",
    "    def __init__(self):\n",
    "        # zum Speichern der aktuellen Input Tensoren\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "        self.n_examples = None\n",
    "        self.n_classes = None\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        # Batchsize und Klassenanzahl auslesen\n",
    "        self.n_examples, self.n_classes = z.shape\n",
    "\n",
    "        # Teacher speichern\n",
    "        self.t = t\n",
    "\n",
    "        # Softmax-Ausgabe berechnen und speichern\n",
    "        # Um numerische Instabilitaeten zu vermeiden, sollte das Maximum der Logits\n",
    "        # subtrahiert werden bevor die Exponentialfunktion angewendet wird. Das\n",
    "        # Softmax-Ergebnis bleibt dadurch unveraendert.\n",
    "        exp_z = np.exp(z - z.max())\n",
    "        self.y = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "        # Cross Entropy `e_ce` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (5)]\n",
    "\n",
    "        # Ergebnisse zurueckgeben\n",
    "        return self.y, e_ce\n",
    "\n",
    "    def backward(self):\n",
    "        # Teacher in 1-aus-n-Kodierung (engl.: one-hot encoding) umwandeln\n",
    "        t_one_hot = np.zeros((self.n_examples, self.n_classes))\n",
    "        t_one_hot[range(self.n_examples), self.t] = 1\n",
    "\n",
    "        # Gradienten bestimmen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Verständnisfrage:*\n",
    "\n",
    "Beeinflusst die konkrete Umsetzung der Reduktion der Fehler aller Beispiele eines Batches auf ein Skalar die Wahl der Lernrate?\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<ul>\n",
    "    <li>Bei einer Reduktion durch den Mittelwert geht der Faktor $\\frac{1}{b}$ (Batchsize $b$) mit in die Gradienten ein.</li>\n",
    "    <li>Bei einer Reduktion durch die Summe fehlt dieser Faktor.</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"netzwerk\"></a>\n",
    "**Abschließend kann eine Klasse `CNN` zur Realisierung des gesamten Netzwerks implementiert werden.**\n",
    "Die zu realisierende Klasse soll:\n",
    "- alle Schichten und Gewichte speichern\n",
    "- die Forward Propagation umsetzen\n",
    "- die Backpropagation umsetzen und die Gradienten für alle Gewichte zurückgeben\n",
    "\n",
    "\n",
    "*Implementierung:*\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Funktionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.copy</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.copy.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.reshape</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.reshape.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, w_1, b_1, w_3, b_3):\n",
    "        # Gewichte kopieren, damit sie spaeter nochmal verwendet werden koennen\n",
    "        w_1_ = w_1.copy()\n",
    "        b_1_ = b_1.copy()\n",
    "        w_3_ = w_3.copy()\n",
    "        b_3_ = b_3.copy()\n",
    "\n",
    "        # Schicht 1 `self.conv` anlegen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (7)]\n",
    "\n",
    "        # Schicht 2 `self.maxpool` anlegen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (8)]\n",
    "\n",
    "        # Schicht 3 `self.fc` anlegen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (9)]\n",
    "\n",
    "    def named_parameters(self):\n",
    "        return {'w_1': self.conv.weight,\n",
    "                'b_1': self.conv.bias,\n",
    "                'w_3': self.fc.weight,\n",
    "                'b_3': self.fc.bias}\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        n_examples = input_tensor.shape[0]\n",
    "\n",
    "        # Schicht 1: `o_1` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (10)]\n",
    "\n",
    "        # Schicht 2: `o_2` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (11)]\n",
    "\n",
    "        # Uebergang zu vollverschalteten Schichten\n",
    "        o_2_flat = o_2.reshape(n_examples, 12)\n",
    "\n",
    "        # Schicht 3: `z_3` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (12)]\n",
    "\n",
    "        return z_3\n",
    "\n",
    "    def backward(self, output_tensor_grad):\n",
    "        # Schicht 3: `dedb_3`, `dedw_3` und `dedo_2` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (13)]\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (14)]\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (15)]\n",
    "\n",
    "        # Uebergang zurueck von vollverschalteter Schicht\n",
    "        dedo_2_spatial = dedo_2.reshape(dedo_2.shape[0], 3, 2, 2)\n",
    "\n",
    "        # Schicht 2: `dedo_1` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (16)]\n",
    "\n",
    "        # Schicht 1: `dedb_1` und `dedw_1` berechnen\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (17)]\n",
    "        # bitte Code ergaenzen <---------------- [Luecke (18)]\n",
    "\n",
    "        # Gradienten fuer alle Gewichte zurueckgeben\n",
    "        return {'w_1': dedw_1,\n",
    "                'b_1': dedb_1,\n",
    "                'w_3': dedw_3,\n",
    "                'b_3': dedb_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Definition der Netzwerkeingabe und der Gewichte*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Tensor mit Groesse 2x1x5x5 definieren\n",
    "x = np.array([[[[0, -1, 0, -1, -2],\n",
    "                [-1, 1, -2, 0, 0],\n",
    "                [2, 0, 0, 1, 1],\n",
    "                [1, -1, 0, -1, -1],\n",
    "                [2, 0, -2, 0, 1]]],\n",
    "              [[[1, 0, -1, 0, -2],\n",
    "                [-1, 2, 0, 1, 1],\n",
    "                [0, 0, 1, 0, -1],\n",
    "                [1, 0, -2, 1, 0],\n",
    "                [0, -2, 0, 0, 0]]]], dtype='float32')\n",
    "\n",
    "# Teacher Tensor definieren\n",
    "t = np.array([0, 1], dtype='int')\n",
    "\n",
    "# Schicht 1\n",
    "# Filter\n",
    "w_1 = np.array([[[[2.0, -1.0],\n",
    "                  [1.0, 2.0]]],\n",
    "                [[[-2.0, 1.0],\n",
    "                  [2.0, -1.0]]],\n",
    "                [[[1.0, 0.0],\n",
    "                  [-1.0, 1.0]]]], dtype='float32')\n",
    "# Bias\n",
    "b_1 = np.array([1, 1, 1], dtype='float32')\n",
    "\n",
    "# Schicht 3\n",
    "# Gewichtsmatrix\n",
    "w_3 = np.array([[1, 1, 1, 0, 0, 0, -1, -1, -1, 0, 0, 0],\n",
    "                [-1, -1, -1, 1, 1, 1, 0, 0, 0, 1, 1, 1]],\n",
    "               dtype='float32')\n",
    "\n",
    "# Bias\n",
    "b_3 = np.array([1, 1], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Anwendung des Netzwerks:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkobjekt anlegen\n",
    "network = CNN(w_1, b_1, w_3, b_3)\n",
    "\n",
    "# Objekt fuer Softmax-Ausgabe und Kreuzentropie anlegen\n",
    "loss = SoftmaxCrossEntropy()\n",
    "\n",
    "# Forward Propagation: `z`, `y` und `e_ce` berechnen\n",
    "# bitte Code ergaenzen <---------------- [Luecke (19)]\n",
    "# bitte Code ergaenzen <---------------- [Luecke (20)]\n",
    "\n",
    "# Ergebnisse der Forward Propagation ausgeben\n",
    "print_tensors(tensors=(y, e_ce),\n",
    "              labels=('y bzw. o_3', 'E'),\n",
    "              precision=4)\n",
    "\n",
    "# Backpropagation\n",
    "dedz = loss.backward()\n",
    "gradients = network.backward(dedz)\n",
    "\n",
    "# Gradienten ausgeben\n",
    "print_tensors(tensors=list(gradients.values()),\n",
    "              labels=[f'{k}.grad' for k in gradients.keys()],\n",
    "              precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "y bzw. o_3:\n",
    "[[0.0474 0.9526]\n",
    " [0.0025 0.9975]]\n",
    "E:\n",
    "1.5255\n",
    "w_1.grad:\n",
    "[[[[-2.3777  2.3765]\n",
    "   [-2.8503 -0.4726]]]\n",
    " [[[-1.9014  0.9464]\n",
    "   [ 0.9513 -0.9501]]]\n",
    " [[[-0.0012 -1.4264]\n",
    "   [-2.8515  0.4713]]]]\n",
    "b_1.grad:\n",
    "[-2.3753  1.9002  1.9002]\n",
    "w_3.grad:\n",
    "[[-2.3728 -1.8977 -2.8552 -0.9489 -3.8041 -1.9002 -2.3765 -1.4214 -1.4227\n",
    "  -1.4276 -0.9489 -1.4227]\n",
    " [ 2.3728  1.8977  2.8552  0.9489  3.8041  1.9002  2.3765  1.4214  1.4227\n",
    "   1.4276  0.9489  1.4227]]\n",
    "b_3.grad:\n",
    "[-0.4751  0.4751]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"d\"></a>\n",
    "### (d) Realisieren Sie den Optimierungsschritt in NumPy und führen Sie für alle Gewichte zwei Updateschritte durch.\n",
    "\n",
    "Als Optimierer soll Stochastic Gradient Descent (SGD) mit einer Lernrate $\\eta = 0.01$ und einem klassischen Momentum von $\\gamma = 0.8$ zum Einsatz kommen.\n",
    "Zusätzlich soll ein ergänzendes Weight Decay mit $\\lambda = 0.01$ verwendet werden.\n",
    "\n",
    "Verwenden Sie die an PyTorch angelehnte Update-Formel:\n",
    "\\begin{equation}\n",
    "v_t \\leftarrow \\gamma \\cdot v_{t-1} + \\left(\\frac{\\partial E}{\\partial \\theta} + \\lambda \\cdot \\theta \\right)\\quad \\text{mit: }v_0 = 0 \\\\\n",
    "\\theta_{t+1} \\leftarrow \\theta_t - \\eta \\cdot v_t\n",
    "\\end{equation}\n",
    "\n",
    "*Implementierung:*\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende Funktion könnte für die Vervollständigung der Lücken hilfreich sein:\n",
    "<ul style=\"margin-bottom: 0px; margin-top: 0px\">\n",
    "    <li><code style=\"background-color: #FAEAEA; padding: 0px\">np.zeros_like</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html\" target=\"_blank\">NumPy-Dokumentation</a>\n",
    "        </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, parameters, lr, momentum=0.0, weight_decay=0.0):\n",
    "        # Parameter speichern\n",
    "        self.parameters = parameters\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        # Velocities initialisieren\n",
    "        self.velocities = {name: np.zeros_like(value)\n",
    "                           for name, value in self.parameters.items()}\n",
    "\n",
    "    def step(self, gradients):\n",
    "        for name in self.parameters:\n",
    "            # fuer jeden Parameter\n",
    "\n",
    "            weight = self.parameters[name]\n",
    "            velocity = self.velocities[name]\n",
    "            grad = gradients[name]\n",
    "\n",
    "            # neue Velocity `velocity` bestimmen\n",
    "            # bitte Code ergaenzen <---------------- [Luecke (21)]\n",
    "\n",
    "            # Velocity speichern fuer naechsten Updateschritt\n",
    "            self.velocities[name] = velocity\n",
    "\n",
    "            # neue Gewichte bestimmen (inplace)\n",
    "            # bitte Code ergaenzen <---------------- [Luecke (22)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Zwei Optimierungsschritte ausführen:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Netzwerkobjekt anlegen\n",
    "network = CNN(w_1, b_1, w_3, b_3)\n",
    "\n",
    "# Objekt fuer Softmax-Ausgabe und Kreuzentropie anlegen\n",
    "loss = SoftmaxCrossEntropy()\n",
    "\n",
    "# Optimiererobjekt erstellen\n",
    "optimizer = SGD(network.named_parameters(),\n",
    "                lr=0.01, momentum=0.8, weight_decay=0.01)\n",
    "\n",
    "# Updateschritte\n",
    "for epoch in range(2):\n",
    "    print(f\"{'-'*40}\\nEpoche {epoch+1}:\")\n",
    "\n",
    "    # Forward Propagation: `z`, `y` und `e_ce` berechnen\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (23)]\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (24)]\n",
    "\n",
    "    # Ergebnisse der Forward Propagation ausgeben\n",
    "    print_tensors(tensors=(y, e_ce),\n",
    "                  labels=('y bzw. o_3', 'E'),\n",
    "                  precision=4)\n",
    "\n",
    "    # Backpropagation\n",
    "    dedz = loss.backward()\n",
    "    gradients = network.backward(dedz)\n",
    "\n",
    "    # Gradienten ausgeben\n",
    "    # print_tensors(tensors=list(gradients.values()),\n",
    "    #               labels=[f'{k}.grad' for k in gradients.keys()],\n",
    "    #               precision=4)\n",
    "\n",
    "    # Optimierungsschritt ausfuehren\n",
    "    optimizer.step(gradients)\n",
    "\n",
    "    # neue Gewichte ausgeben\n",
    "    print_tensors(tensors=list(network.named_parameters().values()),\n",
    "                  labels=list(network.named_parameters().keys()),\n",
    "                  precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "----------------------------------------\n",
    "Epoche 1:\n",
    "y bzw. o_3:\n",
    "[[0.0474 0.9526]\n",
    " [0.0025 0.9975]]\n",
    "E:\n",
    "1.5255\n",
    "w_1:\n",
    "[[[[ 2.0236 -1.0237]\n",
    "   [ 1.0284  2.0045]]]\n",
    " [[[-1.9808  0.9904]\n",
    "   [ 1.9903 -0.9904]]]\n",
    " [[[ 0.9999  0.0143]\n",
    "   [-0.9714  0.9952]]]]\n",
    "b_1:\n",
    "[1.0237 0.9809 0.9809]\n",
    "w_3:\n",
    "[[ 1.0236  1.0189  1.0285  0.0095  0.038   0.019  -0.9761 -0.9857 -0.9857\n",
    "   0.0143  0.0095  0.0142]\n",
    " [-1.0236 -1.0189 -1.0285  0.9904  0.9619  0.9809 -0.0238 -0.0142 -0.0142\n",
    "   0.9856  0.9904  0.9857]]\n",
    "b_3:\n",
    "[1.0047 0.9951]\n",
    "----------------------------------------\n",
    "Epoche 2:\n",
    "y bzw. o_3:\n",
    "[[0.5472 0.4528]\n",
    " [0.0408 0.9592]]\n",
    "E:\n",
    "0.3223\n",
    "w_1:\n",
    "[[[[ 2.0529 -1.0536]\n",
    "   [ 1.0643  2.0095]]]\n",
    " [[[-1.9572  0.9794]\n",
    "   [ 1.9783 -0.9787]]]\n",
    " [[[ 1.0003  0.0321]\n",
    "   [-0.9362  0.9894]]]]\n",
    "b_1:\n",
    "[1.0531 0.9577 0.9575]\n",
    "w_3:\n",
    "[[ 1.0525  1.0418  1.0646  0.021   0.0854  0.0423 -0.9466 -0.9686 -0.9685\n",
    "   0.0321  0.0209  0.0312]\n",
    " [-1.0525 -1.0418 -1.0646  0.9787  0.9143  0.9574 -0.0532 -0.0311 -0.0312\n",
    "   0.9676  0.9788  0.9685]]\n",
    "b_3:\n",
    "[1.0103 0.9891]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width: 5px\">\n",
    "\n",
    "<a name=\"e\"></a>\n",
    "### (e) Reproduzieren Sie die Ergebnisse mit einer PyTorch-Implementierung.\n",
    "\n",
    "\n",
    "---\n",
    "Pakete importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*Netzwerk implementieren:*\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende PyTorch-Definitionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "    <ul style=\"margin-bottom: 0px\">\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Module</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Module.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Conv2d</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.Linear</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.functional.max_pool2d</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.Tensor.view</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.Tensor.view.html#torch.Tensor.view\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyTorchCNN(torch.nn.Module):\n",
    "    def __init__(self, print_tensors=True):\n",
    "        super(PyTorchCNN, self).__init__()\n",
    "\n",
    "        # Schichten anlegen\n",
    "        self.conv = torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=2,\n",
    "                                     stride=1, padding=0, dilation=1, groups=1,\n",
    "                                     bias=True)\n",
    "        self.fc = torch.nn.Linear(in_features=12, out_features=2,\n",
    "                                  bias=True)\n",
    "\n",
    "        # Gewichte mit bereits definierten Variablen initialisieren\n",
    "        self.conv.weight.data = torch.tensor(w_1)\n",
    "        self.conv.bias.data = torch.tensor(b_1)\n",
    "        self.fc.weight.data = torch.tensor(w_3)\n",
    "        self.fc.bias.data = torch.tensor(b_3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o_1 = self.conv(x)\n",
    "        o_2 = F.max_pool2d(o_1, kernel_size=2, stride=2)\n",
    "        o_2_flat = o_2.view(-1, 12)\n",
    "        z_3 = self.fc(o_2_flat)\n",
    "\n",
    "        return z_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Ergebnisse reproduzieren:*\n",
    "\n",
    "<br>\n",
    "<div style=\"background-color: #FAEAEA; padding: 5px; margin: 5px 0px 5px 0px; border-radius: 5px;\">\n",
    "Folgende PyTorch-Definitionen könnten für die Vervollständigung der Lücken hilfreich sein:\n",
    "    <ul style=\"margin-bottom: 0px\">\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.optim.SGD</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.functional.softmax</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "        <li><code style=\"background-color: #FAEAEA;\">torch.nn.functional.cross_entropy</code>&nbsp;&nbsp;&rarr;&nbsp;<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy\" target=\"_blank\">PyTorch-Dokumentation</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netzwerkobjekt anlegen\n",
    "network = PyTorchCNN()\n",
    "\n",
    "# Optimiererobjekt erstellen\n",
    "optimizer = torch.optim.SGD(network.parameters(),\n",
    "                            lr=0.01, momentum=0.8, weight_decay=0.01)\n",
    "\n",
    "# Eingabe und Teacher in PyTorch Tensoren konvertieren\n",
    "x_pytorch = torch.tensor(x)\n",
    "t_pytorch = torch.tensor(t, dtype=torch.long)\n",
    "\n",
    "# Updateschritte\n",
    "for epoch in range(2):\n",
    "    print(f\"{'-'*40}\\nEpoche {epoch+1}:\")\n",
    "\n",
    "    # Forward Propagation: `z`, `y` und `e_ce` berechnen\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (25)]\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (26)]\n",
    "    # bitte Code ergaenzen <---------------- [Luecke (27)]\n",
    "\n",
    "    # Ergebnisse der Forward Propagation ausgeben\n",
    "    print_tensors(tensors=(y, e_ce),\n",
    "                  labels=('y bzw. o_3', 'E'),\n",
    "                  precision=4)\n",
    "\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    e_ce.backward()\n",
    "\n",
    "    # Optimierungsschritt ausfuehren\n",
    "    optimizer.step()\n",
    "\n",
    "    # neue Gewichte ausgeben\n",
    "    print_tensors(tensors=list(dict(network.named_parameters()).values()),\n",
    "                  labels=list(dict(network.named_parameters()).keys()),\n",
    "                  precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>&#9432; <i>Überprüfung &nbsp; &nbsp; <font color=\"CCCCCC\">(anklicken, um Lösung anzuzeigen)</font></i></summary>\n",
    "<code style=\"padding: 0px\">\n",
    "----------------------------------------\n",
    "Epoche 1:\n",
    "y bzw. o_3:\n",
    "[[0.0474 0.9526]\n",
    " [0.0025 0.9975]]\n",
    "E:\n",
    "1.5255\n",
    "conv.weight:\n",
    "[[[[ 2.0236 -1.0237]\n",
    "   [ 1.0284  2.0045]]]\n",
    " [[[-1.9808  0.9904]\n",
    "   [ 1.9903 -0.9904]]]\n",
    " [[[ 0.9999  0.0143]\n",
    "   [-0.9714  0.9952]]]]\n",
    "conv.bias:\n",
    "[1.0237 0.9809 0.9809]\n",
    "fc.weight:\n",
    "[[ 1.0236  1.0189  1.0285  0.0095  0.038   0.019  -0.9761 -0.9857 -0.9857\n",
    "   0.0143  0.0095  0.0142]\n",
    " [-1.0236 -1.0189 -1.0285  0.9904  0.9619  0.9809 -0.0238 -0.0142 -0.0142\n",
    "   0.9856  0.9904  0.9857]]\n",
    "fc.bias:\n",
    "[1.0047 0.9951]\n",
    "----------------------------------------\n",
    "Epoche 2:\n",
    "y bzw. o_3:\n",
    "[[0.5472 0.4528]\n",
    " [0.0408 0.9592]]\n",
    "E:\n",
    "0.3223\n",
    "conv.weight:\n",
    "[[[[ 2.0529 -1.0536]\n",
    "   [ 1.0643  2.0095]]]\n",
    " [[[-1.9572  0.9794]\n",
    "   [ 1.9783 -0.9787]]]\n",
    " [[[ 1.0003  0.0321]\n",
    "   [-0.9362  0.9894]]]]\n",
    "conv.bias:\n",
    "[1.0531 0.9577 0.9575]\n",
    "fc.weight:\n",
    "[[ 1.0525  1.0418  1.0646  0.021   0.0854  0.0423 -0.9466 -0.9686 -0.9685\n",
    "   0.0321  0.0209  0.0312]\n",
    " [-1.0525 -1.0418 -1.0646  0.9787  0.9143  0.9574 -0.0532 -0.0311 -0.0312\n",
    "   0.9676  0.9788  0.9685]]\n",
    "fc.bias:\n",
    "[1.0103 0.9891]\n",
    "</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$_{_\\text{Created for Deep Learning for Computer Vision (DL4CV)}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}